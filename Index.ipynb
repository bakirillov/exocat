{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import nltk\n",
    "import argparse\n",
    "import pymorphy2\n",
    "import pickle as pkl\n",
    "import os.path as op\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatIndex():\n",
    "    \n",
    "    ru = pymorphy2.MorphAnalyzer()\n",
    "    en_linkable = [\"NN\", \"VB\"]\n",
    "    ru_linkable = [\"NOUN\", \"VERB\"]\n",
    "    en_stops = get_stop_words('en')\n",
    "    ru_stops = get_stop_words('ru')\n",
    "    \n",
    "    @classmethod\n",
    "    def empty(C):\n",
    "        g = nx.Graph()\n",
    "        last = None\n",
    "        return(C(g, last))\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(fn):\n",
    "        with open(fn, \"rb\") as ih:\n",
    "            return(pkl.load(ih))\n",
    "        \n",
    "    def __init__(self, g, last):\n",
    "        self.g = g\n",
    "        self.last = last\n",
    "    \n",
    "    @staticmethod\n",
    "    def examine(s, do_implicits=False):\n",
    "        explicits = re.findall(\"\\[\\[\\w+\\]\\]\", s)\n",
    "        explicits = [a.replace(\"[[\", \"\").replace(\"]]\", \"\").lower() for a in explicits]\n",
    "        implicits = []\n",
    "        if do_implicits:\n",
    "            spl = list(\n",
    "                filter(\n",
    "                    lambda x: re.match(\"\\w+\", x) and x not in CatIndex.en_stops and x not in CatIndex.ru_stops, \n",
    "                    re.split(\"\\s\", s)\n",
    "                )\n",
    "            )\n",
    "            for a in spl:\n",
    "                ru = CatIndex.ru.parse(a)\n",
    "                for b in ru:\n",
    "                    for c in CatIndex.ru_linkable:\n",
    "                        if str(b.tag).startswith(c):\n",
    "                            implicits.append(a)\n",
    "                try:\n",
    "                    en = nltk.pos_tag([a])\n",
    "                except:\n",
    "                    pass\n",
    "                else:\n",
    "                    for b in en:\n",
    "                        for c in CatIndex.en_linkable:\n",
    "                            if b[1].startswith(c):\n",
    "                                implicits.append(a)\n",
    "        r = {\n",
    "            \"explicits\": explicits, \"implicits\": implicits\n",
    "        }\n",
    "        return(r)\n",
    "    \n",
    "    def save(self, fn):\n",
    "        with open(fn, \"wb\") as oh:\n",
    "            pkl.dump(self, oh)\n",
    "    \n",
    "    def index(self, list_of_files, do_implicits=False):\n",
    "        lst = sorted(\n",
    "            deepcopy(list_of_files), \n",
    "            key=lambda x: int(op.split(x)[-1].replace(\".md\", \"\"))\n",
    "        )\n",
    "        if self.last:\n",
    "            lst = lst[lst.index(self.last):]\n",
    "        for a in tqdm(list_of_files):\n",
    "            with open(a, \"r\") as ih:\n",
    "                a_file = ih.read().lower()\n",
    "            a_linkables = CatIndex.examine(a_file, do_implicits)\n",
    "            a_cid = op.split(a)[-1].replace(\".md\", \"\")\n",
    "            for b in lst:\n",
    "                if a != b:\n",
    "                    with open(b, \"r\") as ih:\n",
    "                        b_file = ih.read()\n",
    "                    b_linkables = CatIndex.examine(b_file, do_implicits)\n",
    "                    ebunch = {}\n",
    "                    add_edge = False\n",
    "                    for c in b_linkables:\n",
    "                        ints = list(\n",
    "                            set(a_linkables[c]).intersection(set(b_linkables[c]))\n",
    "                        )\n",
    "                        if len(ints) > 0:\n",
    "                            add_edge = True\n",
    "                            ebunch[c] = \",\".join(ints)\n",
    "                        else:\n",
    "                            add_edge = False\n",
    "                        if add_edge:\n",
    "                            b_cid = op.split(b)[-1].replace(\".md\", \"\")\n",
    "                            self.g.add_edges_from([(a_cid, b_cid, ebunch)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = CatIndex.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [a for a in os.walk(\"/home/bakirillov/exocortex/cards/\")][0][2]\n",
    "files = list(filter(lambda x: \".md\" in x, [op.join(\"/home/bakirillov/exocortex/cards/\", a) for a in files]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "I.index(files, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = [a for a in I.g.edges]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01062020193116', '01062020194307'),\n",
       " ('01062020193116', '15062020115055'),\n",
       " ('01062020194307', '15062020115055'),\n",
       " ('15062020115055', '09062020203928'),\n",
       " ('15062020115055', '11062020065219'),\n",
       " ('01062020131840', '01062020092806'),\n",
       " ('01062020092806', '02062020000421'),\n",
       " ('07062020112220', '07062020105212'),\n",
       " ('07062020112220', '13062020070230'),\n",
       " ('07062020105212', '13062020070230'),\n",
       " ('10062020021421', '12062020015744'),\n",
       " ('10062020021421', '13062020140024'),\n",
       " ('12062020015744', '08062020103846'),\n",
       " ('09062020203928', '11062020065219'),\n",
       " ('06062020215251', '06062020222710'),\n",
       " ('06062020215251', '10062020112919'),\n",
       " ('06062020222710', '10062020112919')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "I.save(\"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = CatIndex.load(\"test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
